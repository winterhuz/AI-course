  
因為接著就要開始摸索神經網絡強化學習相關的東西了  
這兩周打算從"會使用模型"、"了解模型原理"開始著手  
  
  
第一個打算嘗試的是OPENCV內建的人臉辨識模型  
進入到 venv/lib/python3.8/site-packages/cv2/data  
可以看到裡面有大量的.xml文件，裡邊每一個都是預訓練的模型  
由文件名可以知道都是使用了HAAR特徵訓練而得，那haar特徵述算又是甚麼呢?  
  
其實可以簡單地理解為一種近似的方法  
考慮了人的鼻子兩側有陰影顏色通常比中間要深  
眼睛有陰影比臉頰要深、嘴唇中間比上下要深等等特徵  
用符合特徵的黑白模板去檢索圖片中是否有地方符合  
再通過條件判定便能找出人臉。  
   
當然這其中有很多技術成分　  
－首先是矩形特徵的區隔，共有三種特徵原型並由此構成矩形特徵   
而矩形特徵可以任意伸縮並套用在灰階圖片上的任意區域   
前面說了人臉有數個特徵模板像是鼻子眼睛等，那要怎麼判斷矩形特徵符合模板呢?  
這便是要看特徵值了，特徵值算法為矩形特徵的白色區域的像素和減去黑色區域像素和  
當然特徵值為了計算量會進行數值歸一化，也就是收斂到０～１附近　　
當一中心矩形特徵對到鼻子，特徵值就會計算白色（鼻子）的像素－黑色（鼻子兩側）的像素　　　
當特徵值在特定闕值內時便會判定符合模板　　


－第二項技術便是積分圖
已知矩形特徵可以投射在任意大小任意位置，特徵值計算為白區減黑區　　
若是使用　‵ｆｏｒ白區內所有像素點‵　這類迴圈計算必然耗費巨大　　

而積分圖只要在初始時遍歷一次從左上到所有像素點的矩形像素和
接著要計算特定區域只需調用三個座標像素值即可完成

－第三項技術即是AdaBoost　級聯分類器　　
已知當矩形特徵的特徵值在特定闕值內時便會判定符合模板　　　
但符合上黑下白的不一定都是眼睛嘛，也有可能是桌腳（？　　　
因此為了增加準確度會事前整合出數個具有辨識度的模板並串在一起　　　　
當範圍內圖片符合眼睛模板，則判定是否符合鼻子，等等等　　
一個級聯分類器是由很多強分類器樹狀構成，強分類器意味著與人臉具高度相關　　
而每個強分類器又由許多弱分類器樹狀構成，弱分類器即可看成是上面所說的模板　　
樹狀構成的緣故使得當某一判斷不通過就不會繼續耗費資源計算　　
由此節省了大量計算成本　　
　　
